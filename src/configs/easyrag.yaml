# 流程参数
rerank_fusion_type: 0 # 0-->不使用精排后fusion 1-->两路检索结果rrf 2-->生成长度最大的作为最终结果 3-->两路生成结果拼接
ans_refine_type: 0 # 0-->不对答案做后处理 1-->LLM利用top1文档和参考答案生成新答案 2-->LLM将top1文档和参考答案拼接生成新答案

# 粗排参数
re_only: false  # 只检索，用于调试检索
retrieval_type: 2 # 1-->密集 2-->稀疏 3-->混合
f_topk: 256 # 仅用于混合检索器最终的fusion数量
f_topk_1: 288 # 密集检索粗排topk
f_topk_2: 192 # 稀疏检索粗排topk
f_topk_3: 6 # 路径搜索粗排topk

# 密集检索器参数
reindex: false  # 是否从头开始构建索引
embedding_name: Alibaba-NLP/gte-Qwen2-7B-instruct
vector_size: 3584
cache_path: "cache" # 用于qdrant 硬盘存储调试
collection_name: "aiops24" # qdrant collection名字

# 稀疏检索器参数
bm25_type: 0 # 0-->官方实现 1-->bm25s实现，速度更快

# 重排器参数
r_topk: 6 # 精排topk
r_topk_1: 6 # 精排后Fusion的topk
reranker_name: ../models/bge-reranker-v2-minicpm-layerwise
use_reranker: 2 # 0-->不使用 1-->ST的普通Reranker 2-->bge LLM Reranker
r_embed_bs: 32
r_use_efficient: 0 # 0-->不加速 1-->使用最大值选择方法加速 2-->使用熵选择方法加速

# 生成参数
llm_keys: [
  "your-keys",
  "your-keys",
]
llm_name: "glm-4"
llm_embed_type: 3 # 最终的上下文文档编码参数

# 文本排序编码方式
f_embed_type_1: 1 # 密集检索的文档编码方式
f_embed_type_2: 2 # 稀疏检索的文档编码方式
r_embed_type: 1 # 重排的文档编码方式

# 分块策略
split_type: 0 # 0-->Sentence 1-->Hierarchical
chunk_size: 1024
chunk_overlap: 200

# 路径参数
data_path: "../data/format_data_with_img"
hfmodel_cache_folder: "../../../../hf_cache/hub"
qdrant_url: "http://localhost:6333"

# 本地LLM参数
# local_llm_name: "Qwen/Qwen2-7B-Instruct"

# 上下文压缩参数
compress_method: "" # bm25_extract llmlingua longllmlingua
compress_rate: 0.5

# 虚假文档参数
hyde: false
hyde_merging: false